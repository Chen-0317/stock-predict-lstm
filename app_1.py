import streamlit as st
import yfinance as yf
import numpy as np
import pandas as pd
import tensorflow as tf
import random
import os
import pandas_ta as ta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.optimizers import Adam
import plotly.graph_objects as go

def set_seed(seed=42):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)

def prepare_stock_data(df, lookback=100, predict_days=5):
    # å±•å¹³æ¬„ä½ï¼Œå¦‚æžœæ˜¯ MultiIndex
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = df.columns.droplevel()

    # å¦‚æžœæ¬„ä½åç¨±éƒ½æ˜¯è‚¡ç¥¨ä»£ç¢¼ï¼Œä¾‹å¦‚ '0050.TW'ï¼Œå˜—è©¦è‡ªå‹•é‡å‘½åæ¬„ä½
    if all(col == df.columns[0] for col in df.columns) and isinstance(df.columns[0], str):
        df.columns = ['Open', 'High', 'Low', 'Close', 'Volume']  # å¥—ç”¨æ¨™æº–æ¬„å
        print("ðŸ›  è‡ªå‹•é‡å‘½åæ¬„ä½ç‚ºæ¨™æº–æ ¼å¼ï¼š", df.columns)

    # ç¢ºä¿æ˜¯ DataFrame ä¸”æœ‰ Close æ¬„ä½
    if not isinstance(df, pd.DataFrame) or 'Close' not in df.columns:
        return None, None, "åŽŸå§‹è³‡æ–™éŒ¯èª¤ï¼šä¸æ˜¯ DataFrame æˆ–ç¼ºå°‘ Close æ¬„ä½"

    df = df.sort_index()
    data = df[['Close']].copy()

    print("ðŸ›  DEBUGï¼šdata è³‡æ–™åž‹æ…‹ï¼š", type(data))
    print("ðŸ›  DEBUGï¼šdata['Close'] é¡žåž‹ï¼š", type(data['Close']))
    print("ðŸ›  DEBUGï¼šdata['Close'] é ­éƒ¨å…§å®¹ï¼š\n", data['Close'].head())

    if isinstance(data['Close'], pd.DataFrame):
        data['Close'] = data['Close'].squeeze()

    if data['Close'].isnull().any():
        data['Close'].fillna(method='ffill', inplace=True)

    # MACD è¨ˆç®—
    macd_result = ta.macd(data['Close'])
    
    print("ðŸ›  DEBUGï¼šmacd_result çš„å…§å®¹ï¼š")
    print(macd_result.head())  # é¡¯ç¤ºè¨ˆç®—å¾Œçš„å‰å¹¾ç­†è³‡æ–™
    print("ðŸ›  DEBUGï¼šmacd_result æ˜¯å¦æœ‰ NaNï¼š", macd_result.isna().sum())

    if macd_result is not None and not macd_result.empty:
        data['MACD'] = macd_result['MACD_12_26_9']
        data['MACD_signal'] = macd_result['MACDs_12_26_9']
    else:
        return None, None, "MACD è¨ˆç®—å¤±æ•—ï¼Œè«‹æª¢æŸ¥è³‡æ–™"

    # RSI è¨ˆç®—
    rsi_result = ta.rsi(data['Close'], length=14)
    if rsi_result is not None and not rsi_result.empty:
        data['RSI'] = rsi_result
    else:
        return None, None, "RSI è¨ˆç®—å¤±æ•—ï¼Œè«‹æª¢æŸ¥è³‡æ–™"

    # åŽ»é™¤é›¢ç¾¤å€¼
    Q1 = data['Close'].quantile(0.25)
    Q3 = data['Close'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    data = data[(data['Close'] >= lower_bound) & (data['Close'] <= upper_bound)]

    # æ»¾å‹•å¹³å‡
    data['Close'] = data['Close'].rolling(window=5).mean()

    # åŽ»é™¤å›  MACD/RSI/rolling ç”¢ç”Ÿçš„ NaN
    data.dropna(inplace=True)

    if data.empty:
        return None, None, "è™•ç†å¾Œè³‡æ–™ç‚ºç©º"

    # åªä¿ç•™æ¨¡åž‹ç”¨åˆ°çš„ç‰¹å¾µ
    features = ['Close', 'MACD', 'MACD_signal', 'RSI']
    data = data[features]
    data.dropna(inplace=True)

    # æ¨™æº–åŒ–
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)

    # æ™‚åºè³‡æ–™è£½ä½œ
    X, y = [], []
    for i in range(lookback, len(scaled_data) - predict_days + 1):
        X.append(scaled_data[i - lookback:i])
        y.append(scaled_data[i:i + predict_days, 0])  # åªé æ¸¬ Close

    return np.array(X), np.array(y), scaler

def train_lstm_model(X, y, predict_days):
    model = Sequential([
        Input(shape=(X.shape[1], X.shape[2])),
        LSTM(128, return_sequences=True),
        LSTM(64),
        Dropout(0.2),
        Dense(predict_days)
    ])
    optimizer = Adam(learning_rate=0.0001)
    model.compile(optimizer=optimizer, loss='mse')

    # ä½¿ç”¨ st.progress() é¡¯ç¤ºè¨“ç·´é€²åº¦æ¢
    progress_bar = st.progress(0)  # åˆå§‹é€²åº¦ç‚º 0
    
    # è¨“ç·´æ¨¡åž‹ä¸¦æ›´æ–°é€²åº¦æ¢
    for epoch in range(100):
        model.fit(X, y, epochs=1, batch_size=32, verbose=0,
                  validation_split=0.2, callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])

        # æ›´æ–°é€²åº¦æ¢
        progress = (epoch + 1) / 100
        progress_bar.progress(progress)

    return model

def time_series_cross_validation(data, lookback, predict_days, n_splits=5):
    errors = []
    progress_bar = st.progress(0.0)  # åˆå§‹åŒ–é€²åº¦æ¢
    
    for split in range(n_splits):
        # ===== é€²åº¦æ¢æ›´æ–° =====
        progress_bar.progress((split + 1) / n_splits)
        
        train_size = int(len(data) * (split + 1) / n_splits)
        train_data = data[:train_size]
        
        try:
            val_data = data[train_size:train_size + predict_days, 0]  # åªçœ‹ close
        except IndexError:
            st.warning("âš  è³‡æ–™åˆ‡ç‰‡éŒ¯èª¤ï¼Œè·³éŽé€™ä¸€çµ„ split")
            continue

        if len(val_data) < predict_days:
            continue

        X, y = [], []
        for i in range(lookback, len(train_data) - predict_days + 1):
            X.append(train_data[i - lookback:i])
            y.append(train_data[i:i + predict_days, 0])
        X, y = np.array(X), np.array(y)

        model = Sequential([
            Input(shape=(X.shape[1], X.shape[2])),
            LSTM(64, return_sequences=True),
            LSTM(32),
            Dense(predict_days)
        ])
        model.compile(optimizer='adam', loss='mse')
        model.fit(X, y, epochs=10, batch_size=32, verbose=0, 
                  validation_split=0.2,  callbacks=[EarlyStopping(patience=2, restore_best_weights=True)])

        val_sequence = data[train_size - lookback:train_size]
        val_sequence = np.expand_dims(val_sequence, axis=0)
        predicted = model.predict(val_sequence)
        mse = mean_squared_error(val_data, predicted.flatten())
        errors.append(mse)
        
    progress_bar.progress(1.0)  # è¨“ç·´å®Œæˆï¼Œé€²åº¦æ¢è¨­ç‚º 100%
    return np.mean(errors)

# ========== Streamlit UI ==========
st.title("ðŸ“ˆ è‚¡ç¥¨åƒ¹æ ¼é æ¸¬ - LSTM æ¨¡åž‹ (å« RSI + MACD)")
option = st.selectbox("é¸æ“‡æ“ä½œ", ("ä¸€èˆ¬é æ¸¬", "æ™‚é–“åºåˆ—äº¤å‰é©—è­‰"))
ticker_input = st.text_input("è¼¸å…¥è‚¡ç¥¨ä»£ç¢¼ï¼ˆå¦‚ 0050.TWï¼‰", "0050.TW")
predict_days = 5
lookback = 100

if option == "ä¸€èˆ¬é æ¸¬":
    if st.button("é–‹å§‹é æ¸¬"):
        set_seed()
        with st.spinner("ä¸‹è¼‰è³‡æ–™èˆ‡é æ¸¬ä¸­..."):
            df = yf.download(ticker_input, period="10y")
            if df.empty:
                st.error("æ‰¾ä¸åˆ°è‚¡ç¥¨è³‡æ–™")
            else:
                X, y, scaler_or_msg = prepare_stock_data(df, lookback, predict_days)
                if X is None:
                    st.error(scaler_or_msg)
                else:
                    n_models = 3
                    all_predictions = []
                    
                    for i in range(n_models):
                        st.write(f"ðŸ” ç¬¬ {i+1} æ¬¡æ¨¡åž‹è¨“ç·´èˆ‡é æ¸¬")
                        model = train_lstm_model(X, y, predict_days)
                        latest_sequence = X[-1:]
                        predicted = model.predict(latest_sequence)
                        all_predictions.append(predicted.reshape(-1))
                    
                    # å¹³å‡é æ¸¬çµæžœ
                    avg_pred = np.mean(all_predictions, axis=0)
                    
                    # é‚„åŽŸæˆåƒ¹æ ¼
                    avg_prices = scaler_or_msg.inverse_transform(
                        np.hstack([avg_pred.reshape(-1, 1), np.zeros((predict_days, 3))])
                    )[:, 0]
                    
                    future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=predict_days, freq='B')
                    pred_df_avg = pd.DataFrame({'Date': future_dates, 'Price': avg_prices, 'Type': 'å¹³å‡é æ¸¬'})
                    
                    # æ¯æ¬¡çš„é æ¸¬ä¹Ÿåšå‡º DataFrameï¼ˆå¯é¸ï¼‰
                    indiv_dfs = []
                    for i, pred in enumerate(all_predictions):
                        prices = scaler_or_msg.inverse_transform(
                            np.hstack([pred.reshape(-1, 1), np.zeros((predict_days, 3))])
                        )[:, 0]
                        df_pred = pd.DataFrame({'Date': future_dates, 'Price': prices, 'Type': f'ç¬¬{i+1}æ¬¡é æ¸¬'})
                        indiv_dfs.append(df_pred)
                    
                    # åˆä½µæ‰€æœ‰é æ¸¬
                    df_plot = df[['Close']].reset_index().rename(columns={'Date': 'Date', 'Close': 'Price'})
                    df_plot['Type'] = 'æ­·å²åƒ¹æ ¼'
                    combined_df = pd.concat([df_plot] + indiv_dfs + [pred_df_avg])

                    predicted_prices = scaler_or_msg.inverse_transform(
                        np.hstack([predicted.reshape(-1, 1),
                                   np.zeros((predict_days, 3))])
                    )[:, 0]  # åªå–é‚„åŽŸå¾Œçš„ Close
                    future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=predict_days, freq='B')
                    pred_df = pd.DataFrame({'Date': future_dates, 'Predicted Price': predicted_prices})

                    df_plot = df[['Close']].reset_index().rename(columns={'Date': 'Date', 'Close': 'Price'})
                    df_plot['Type'] = 'æ­·å²åƒ¹æ ¼'
                    pred_df['Type'] = 'é æ¸¬åƒ¹æ ¼'
                    pred_df.rename(columns={'Predicted Price': 'Price'}, inplace=True)
                    combined_df = pd.concat([df_plot, pred_df])

                    fig = go.Figure()
                    for name, group in combined_df.groupby("Type"):
                        fig.add_trace(go.Scatter(x=group["Date"], y=group["Price"],
                                                 mode="lines+markers" if name == "é æ¸¬åƒ¹æ ¼" else "lines",
                                                 name=name))
                    fig.update_layout(title=f"{ticker_input} æœªä¾† {predict_days} å¤©é æ¸¬",
                                      xaxis_title="æ—¥æœŸ", yaxis_title="è‚¡åƒ¹", template="plotly_white")
                    st.plotly_chart(fig)
                    st.dataframe(pred_df.set_index('Date'))

elif option == "æ™‚é–“åºåˆ—äº¤å‰é©—è­‰":
    if st.button("é–‹å§‹é©—è­‰"):
        set_seed()
        with st.spinner("åŸ·è¡Œäº¤å‰é©—è­‰ä¸­..."):
            df = yf.download(ticker_input, period="10y")
            if df.empty:
                st.error("æ‰¾ä¸åˆ°è‚¡ç¥¨è³‡æ–™")
            else:
                X, y, scaler_or_msg = prepare_stock_data(df, lookback, predict_days)
                if X is None:
                    st.error(scaler_or_msg)
                else:
                    scaled_data = X.reshape(-1, X.shape[2])  # é‚„åŽŸæˆ 2D çµæ§‹
                    mean_mse = time_series_cross_validation(scaled_data, lookback, predict_days, n_splits=3)
                    st.write(f"âœ… äº¤å‰é©—è­‰å¹³å‡ MSEï¼š{mean_mse:.4f}")
